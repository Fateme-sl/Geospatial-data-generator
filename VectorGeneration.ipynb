{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9420ef69-628b-40f8-bfa9-746948c0a740",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '10402   262 V-AFI-A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14576\\1021891910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[0mvalues_file_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/VOLMET_LINESIDX.DAT\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[0mcontour_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_values_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues_file_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14576\\1021891910.py\u001b[0m in \u001b[0;36mread_values_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mcontour_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparts\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontour_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;31m#print(f\"Contour ID: {contour_id}, Value: {value}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '10402   262 V-AFI-A'"
     ]
    }
   ],
   "source": [
    "#Preparing text files and converting them to json-polygon types, and also assign the values to each polygon based on their index!\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "\n",
    "class GeoPoint:\n",
    "    def __init__(self, longitude, latitude):\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "\n",
    "\n",
    "class Contour:\n",
    "    def __init__(self):\n",
    "        self.noPoints = 0\n",
    "        self.points = []\n",
    "\n",
    "\n",
    "IDWM_Contours = {}\n",
    "\n",
    "def parse_coordinates(coordinates):\n",
    "    latDeg = int(coordinates[0:2])\n",
    "    latMin = int(coordinates[2:4])\n",
    "    latSec = int(coordinates[4:6])\n",
    "    NS = coordinates[6]\n",
    "    lonDeg = int(coordinates[7:10])\n",
    "    lonMin = int(coordinates[10:12])\n",
    "    lonSec = int(coordinates[12:14])\n",
    "    EW = coordinates[14]\n",
    "\n",
    "    longitude = lonDeg + lonMin / 60.0 + lonSec / 3600.0\n",
    "\n",
    "    if EW == \"W\":\n",
    "        longitude = -longitude    \n",
    "\n",
    "    latitude = latDeg + latMin / 60.0 + latSec / 3600.0\n",
    "\n",
    "    if NS == \"S\":\n",
    "        latitude = -latitude\n",
    "\n",
    "    return longitude, latitude\n",
    "\n",
    "def parse_lines(lines):\n",
    "    for line in lines:\n",
    "        trimmed = line.strip()\n",
    "        parts = trimmed.split()\n",
    "\n",
    "        if len(parts) == 4:  # index reference 10001 1 5745 0\n",
    "            contourID = int(parts[0])\n",
    "            first = int(parts[1])\n",
    "            last = int(parts[2])\n",
    "            dummy = int(parts[3])\n",
    "\n",
    "            if contourID not in IDWM_Contours:\n",
    "                IDWM_Contours[contourID] = Contour()\n",
    "\n",
    "            IDWM_Contours[contourID].noPoints = last\n",
    "        elif len(parts) == 2:  # points\n",
    "            coordinates, point_no = parts[0], int(parts[1])\n",
    "\n",
    "            if contourID not in IDWM_Contours:\n",
    "                IDWM_Contours[contourID] = Contour()\n",
    "\n",
    "            longitude, latitude = parse_coordinates(coordinates)\n",
    "            IDWM_Contours[contourID].points.append(GeoPoint(longitude, latitude))\n",
    "\n",
    "\n",
    "def geo_point_to_dict(geo_point):\n",
    "    return OrderedDict([(\"type\", \"Point\"), (\"coordinates\", [geo_point.longitude, geo_point.latitude])])\n",
    "\n",
    "\n",
    "def contour_to_json(contour, value):\n",
    "    geometry = OrderedDict([\n",
    "        (\"type\", \"Polygon\"),\n",
    "        (\"coordinates\", [[(point.longitude, point.latitude) for point in contour.points]])\n",
    "    ])\n",
    "    feature = OrderedDict([\n",
    "        (\"type\", \"Feature\"),\n",
    "        (\"geometry\", geometry),\n",
    "        (\"contour_id\", contour_id),\n",
    "        (\"value\", value)\n",
    "    ])\n",
    "    \n",
    "    return json.dumps(feature, indent=2)\n",
    "\n",
    "\n",
    "def read_values_file(file_path):\n",
    "    values = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            contour_id = parts [0]\n",
    "            value = \" \".join(parts[1:3])\n",
    "            values[int(contour_id)] = value\n",
    "            #print(f\"Contour ID: {contour_id}, Value: {value}\")\n",
    "    return values\n",
    "    \n",
    "\n",
    "\n",
    "file_path = \"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/LINES.txt\"\n",
    "\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "parse_lines(lines)\n",
    "\n",
    "values_file_path = \"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/VOLMET_LINESIDX.DAT\"\n",
    "contour_values = read_values_file(values_file_path)\n",
    "\n",
    "\n",
    "\n",
    "output_directory=\"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/OUTPUT/JSONs\"\n",
    "for contour_id, contour in IDWM_Contours.items():\n",
    "    json_data = contour_to_json(contour, contour_values.get(contour_id, 0))  # Assign a default value of 0 if not found in the file\n",
    "    output_file_path = os.path.join(output_directory,f\"contour_{contour_id}.json\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        output_file.write(json_data)\n",
    "\n",
    "        \n",
    "        \n",
    "print(\"done\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50186687-c064-4f9b-8e14-7a6d7ec68725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in L1: 243\n",
      "Points in L2: 291\n",
      "Points in L1: 207\n",
      "Points in L2: 200\n",
      "Points in L1: 110\n",
      "Points in L2: 281\n",
      "Points in L1: 24\n",
      "Points in L2: 209\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "###Additional lines for correcting the contours with the IDL problem\n",
    "###split the contours by this code!\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "class GeoPoint:\n",
    "    def __init__(self, longitude, latitude):\n",
    "        self.longitude = longitude\n",
    "        self.latitude = latitude\n",
    "\n",
    "\n",
    "class Contour:\n",
    "    def __init__(self):\n",
    "        self.noPoints = 0\n",
    "        self.points = []\n",
    "\n",
    "def separate_polygon(points):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "\n",
    "    for gp in points:\n",
    "        if gp.longitude < -47:\n",
    "            l1.append(gp)\n",
    "        else:\n",
    "            l2.append(gp)\n",
    "            \n",
    "    #print(\"Avg Longitude:\", avg_longitude)\n",
    "    print(\"Points in L1:\", len(l1))\n",
    "    print(\"Points in L2:\", len(l2))\n",
    "\n",
    "    return l1, l2\n",
    "\n",
    "def close_contour_if_needed(points):\n",
    "\n",
    "    if len (points) >= 2 and points[0] != points[-1]:\n",
    "        points.append(points[0])\n",
    "\n",
    "IDWM_Contours = {}\n",
    "\n",
    "def parse_coordinates(coordinates, contourID):\n",
    "    latDeg = int(coordinates[0:2])\n",
    "    latMin = int(coordinates[2:4])\n",
    "    latSec = int(coordinates[4:6])\n",
    "    NS = coordinates[6]\n",
    "    lonDeg = int(coordinates[7:10])\n",
    "    lonMin = int(coordinates[10:12])\n",
    "    lonSec = int(coordinates[12:14])\n",
    "    EW = coordinates[14]\n",
    "\n",
    "    longitude = lonDeg + lonMin / 60.0 + lonSec / 3600.0\n",
    "\n",
    "    if EW == \"W\":\n",
    "        longitude= -longitude  \n",
    "\n",
    "    latitude = latDeg + latMin / 60.0 + latSec / 3600.0\n",
    "\n",
    "    if NS == \"S\":\n",
    "        latitude = -latitude\n",
    "\n",
    "    return longitude, latitude\n",
    "    \n",
    "def parse_lines(lines):\n",
    "    contourID = None  # Initialize contourID outside the loop\n",
    "    for line in lines:\n",
    "        trimmed = line.strip()\n",
    "        parts = trimmed.split()\n",
    "        \n",
    "        if len(parts) == 4:\n",
    "            contourID = int(parts[0])\n",
    "            if contourID not in IDWM_Contours:\n",
    "                IDWM_Contours[contourID] = Contour()\n",
    "            IDWM_Contours[contourID].noPoints = int(parts[2])\n",
    "        elif len(parts) == 2 and contourID is not None:\n",
    "            coordinates, point_no = parts[0], int(parts[1])\n",
    "            longitude, latitude = parse_coordinates(coordinates, contourID)\n",
    "            IDWM_Contours[contourID].points.append(GeoPoint(longitude, latitude))          \n",
    "\n",
    "def geo_point_to_dict(geo_point):\n",
    "    return OrderedDict([(\"type\", \"Point\"), (\"coordinates\", [geo_point.longitude, geo_point.latitude])])\n",
    "\n",
    "\n",
    "def contour_to_json(contour, value):\n",
    "    geometry = OrderedDict([\n",
    "        (\"type\", \"Polygon\"),\n",
    "        (\"coordinates\", [[(point.longitude, point.latitude) for point in contour.points]])\n",
    "    ])\n",
    "    feature = OrderedDict([\n",
    "        (\"type\", \"Feature\"),\n",
    "        (\"geometry\", geometry),\n",
    "        ((\"value\", value)),\n",
    "        (\"contour\",int(contour_id))\n",
    "    ])\n",
    "    return json.dumps(feature, indent=2)\n",
    "\n",
    "#when we have two value columns\n",
    "def read_values_file(file_path):\n",
    "    values = {}\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            contour_id = parts [0]\n",
    "            value = \" \".join(parts[1:3])\n",
    "            values[int(contour_id)] = value\n",
    "            #print(f\"Contour ID: {contour_id}, Value: {value}\")\n",
    "    return values\n",
    "\n",
    "#when we have only 1 value\n",
    "#def read_calues_file(file_path):\n",
    "    #values = {}\n",
    "    #with open(file_path, \"r\") as file:\n",
    "    #    for line in file:\n",
    "     #       contour_id, value = line.strip().split(\"\\t\")\n",
    "      #      values[int(contour_id)] = float(value)\n",
    "    #return values\n",
    "\n",
    "        \n",
    "file_path = \"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/LINES.txt\"\n",
    "\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "parse_lines(lines)\n",
    "\n",
    "values_file_path = \"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/VOLMET_LINESIDX-edited.txt\"\n",
    "contour_values = read_values_file(values_file_path)\n",
    "\n",
    "for contour_id in [10413,10412,10411,10410]:\n",
    "    if contour_id in IDWM_Contours:\n",
    "        l1, l2 = separate_polygon(IDWM_Contours[contour_id].points)\n",
    "        IDWM_Contours[contour_id].points = l1\n",
    "        if len(l2) > 0:\n",
    "            new_contour_id = contour_id + 1000\n",
    "            new_contour = Contour()  # Create a new contour instance\n",
    "            new_contour.points = l2\n",
    "            IDWM_Contours[new_contour_id] = new_contour  # Add the new contour to the dictionary\n",
    "            #print(\"New Contour ID:\", new_contour_id)\n",
    "            #print(\"Number of Points in New Contour:\", len(new_contour.points))\n",
    "            \n",
    "        \n",
    "        close_contour_if_needed(IDWM_Contours[contour_id].points)\n",
    "        #print(\"Contour\", contour_id, \"Points after closure:\", [gp.longitude for gp in IDWM_Contours[contour_id].points])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "output_directory=\"D:/1_______internship-itu/IDWM-flat files/REG2/VOLMET/OUTPUT/new\"\n",
    "for contour_id, contour in IDWM_Contours.items():\n",
    "    json_data = contour_to_json(contour, contour_values.get(contour_id, 0))  # Assign a default value of 0 if not found in the file\n",
    "    output_file_path = os.path.join(output_directory,f\"contour_{contour_id}.json\")\n",
    "\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        output_file.write(json_data)\n",
    "        \n",
    "       \n",
    "# Print the points of the updated contours\n",
    "#for contour_id in [10004, 10005, 10006]:\n",
    "    #if contour_id in IDWM_Contours:\n",
    "        #print(\"Contour\", contour_id, \"Points:\", IDWM_Contours[contour_id].points)\n",
    "\n",
    "# Add this line at the beginning of the script to see if it's reaching this point\n",
    "#print(\"Starting the script...\")\n",
    "\n",
    "# Add this line after parsing the lines to check the contents of IDWM_Contours\n",
    "#print(IDWM_Contours)\n",
    "\n",
    "# Add this line after reading the values file to check the contour_values dictionary\n",
    "#print(contour_values)\n",
    "\n",
    "# Add this line inside the loop to check the generated JSON data\n",
    "#print(json_data)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4289b86-514b-443d-b2be-5f68650711df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fateme\\anaconda3\\lib\\site-packages\\geopandas\\io\\file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Convert the json files to one gpkg file\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Create an empty DataFrame to hold the data\n",
    "data = []\n",
    "\n",
    "# Set the path to the directory containing the JSON files\n",
    "json_files_directory = \"D:/1_______internship-itu/IDWM-flat files/REG2/RDARA/OUTPUT/new\"\n",
    "\n",
    "# Loop through the JSON files and read them into the DataFrame\n",
    "for file_name in os.listdir(json_files_directory):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_files_directory, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            json_data = json.load(file)\n",
    "            data.append(json_data)\n",
    "\n",
    "# Convert the list of JSON data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame by creating a 'geometry' column\n",
    "geometry = [shape(geom) for geom in df['geometry']]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Convert the GeoDataFrame to a GeoPackage file\n",
    "output_directory = \"D:/1_______internship-itu/IDWM-flat files/REG2/RDARA/OUTPUT/new\"\n",
    "output_gpkg_file = os.path.join(output_directory, \"output_file.gpkg\")\n",
    "gdf.to_file(output_gpkg_file, driver=\"GPKG\")\n",
    "\n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "\n",
    "#output_gpkg_file = \"output_file.gpkg\"\n",
    "#gdf.to_file(output_gpkg_file, driver=\"GPKG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f45048ac-293b-4981-bd70-f85af2eba5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the json files to one json file\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create an empty list to hold the JSON data\n",
    "json_data_list = []\n",
    "\n",
    "# Set the path to the directory containing the JSON files\n",
    "json_files_directory = \"C:/Users/Pooya System/Documents/Python Scripts/REG2/CST/CLO134/CLO134_OUTPUT/CLO50-H\"\n",
    "\n",
    "# Loop through the JSON files and read them into the list\n",
    "for file_name in os.listdir(json_files_directory):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_files_directory, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            json_data = json.load(file)\n",
    "            json_data_list.append(json_data)\n",
    "\n",
    "# Save the list of JSON data as a single JSON file with an array of objects\n",
    "output_json_file = \"output_file.json\"\n",
    "with open(output_json_file, \"w\") as file:\n",
    "    json.dump(json_data_list, file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c52fe49c-6475-4860-9381-11c4e1f74ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert the json files to one Geojson, in order to be readable in QGIS\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "# Create an empty DataFrame to hold the data\n",
    "data = []\n",
    "\n",
    "# Set the path to the directory containing the JSON files\n",
    "json_files_directory = \"C:/Users/Pooya System/Documents/Python Scripts/REG2/CST/CLO134/CLO134_OUTPUT/CLO50-H\"\n",
    "\n",
    "# Loop through the JSON files and read them into the DataFrame\n",
    "for file_name in os.listdir(json_files_directory):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(json_files_directory, file_name)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            json_data = json.load(file)\n",
    "            data.append(json_data)\n",
    "\n",
    "# Convert the list of JSON data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame by creating a 'geometry' column\n",
    "geometry = [shape(geom) for geom in df['geometry']]\n",
    "gdf = gpd.GeoDataFrame(df, geometry=geometry)\n",
    "\n",
    "# Convert the GeoDataFrame to a GeoJSON file\n",
    "output_geojson_file = \"output_file.geojson\"\n",
    "gdf.to_file(output_geojson_file, driver=\"GeoJSON\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd12629-d35e-4dec-8f59-7bc3d2d045c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
